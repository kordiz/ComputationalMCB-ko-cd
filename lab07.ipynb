{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating 100 megabyte of random data, containing 100%, 90%, 80%, 70%, 60%, and 50% zeros, and storing to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104857600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#100% zeros\n",
    "random100 = np.random.choice([0, 1], size=8*1024*1024*100, replace=True, p=[0, 1])\n",
    "zeros_100p = np.packbits(random100)\n",
    "open('zeros_100p', 'wb').write(zeros_100p)\n",
    "\n",
    "#90% zeros\n",
    "random90 = np.random.choice([0, 1], size=8*1024*1024*100, replace=True, p=[0.9, 0.1])\n",
    "zeros_90p = np.packbits(random90)\n",
    "open('zeros_90p', 'wb').write(zeros_90p)\n",
    "\n",
    "#80% zeros\n",
    "random80 = np.random.choice([0, 1], size=8*1024*1024*100, replace=True, p=[0.8, 0.2])\n",
    "zeros_80p = np.packbits(random80)\n",
    "open('zeros_80p', 'wb').write(zeros_80p)\n",
    "\n",
    "#70% zeros\n",
    "random70 = np.random.choice([0, 1], size=8*1024*1024*100, replace=True, p=[0.7, 0.3])\n",
    "zeros_70p = np.packbits(random70)\n",
    "open('zeros_70p', 'wb').write(zeros_70p)\n",
    "\n",
    "#60% zeros\n",
    "random60 = np.random.choice([0, 1], size=8*1024*1024*100, replace=True, p=[0.6, 0.4])\n",
    "zeros_60p = np.packbits(random60)\n",
    "open('zeros_60p', 'wb').write(zeros_60p)\n",
    "\n",
    "#50% zeros\n",
    "random50 = np.random.choice([0, 1], size=8*1024*1024*100, replace=True, p=[0.5, 0.5])\n",
    "zeros_50p = np.packbits(random50)\n",
    "open('zeros_50p', 'wb').write(zeros_50p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating DNA and protein sequences 100 million letters long and writing  to your home directory. The probability of each letter is equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_letters = ['A', 'T', 'C', 'G']\n",
    "aa_letters = ['G', 'A', 'L', 'M', 'F', 'W', 'K', 'Q', 'E', 'S', 'P', 'V', 'I', 'C', 'Y', 'H', 'R', 'N', 'D', 'T']\n",
    "\n",
    "#random DNA sequence of 100 million letters\n",
    "random_dna = np.random.choice(dna_letters, size=100000000, replace=True, p=[0.25, 0.25, 0.25, 0.25])\n",
    "# dna_packed = np.packbits(random_dna)\n",
    "open('nt_seq.fa', 'w').write(''.join(random_dna))\n",
    "\n",
    "#random amino acid sequence of 100 million letters\n",
    "random_aa = np.random.choice(aa_letters, size=100000000, replace=True, p=[1/20]*20)\n",
    "# aa_packed = np.packbits(random_aa)\n",
    "open('protein_seq.fa', 'w').write(''.join(random_aa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressing data in the terminal via gzip:\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time gzip -k zeros_100p\n",
    "\n",
    "    real    0m0.739s\n",
    "    user    0m0.703s\n",
    "    sys     0m0.036s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time gzip -k zeros_90p\n",
    "\n",
    "    real    0m0.002s\n",
    "    user    0m0.000s\n",
    "    sys     0m0.002s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time gzip -k zeros_80p\n",
    "\n",
    "\n",
    "    real    0m20.367s\n",
    "    user    0m16.402s\n",
    "    sys     0m0.152s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time gzip -k zeros_70p\n",
    "\n",
    "    real    0m6.207s\n",
    "    user    0m6.014s\n",
    "    sys     0m0.193s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time gzip -k zeros_60p\n",
    "\n",
    "    real    0m4.312s\n",
    "    user    0m4.156s\n",
    "    sys     0m0.157s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time gzip -k zeros_50p\n",
    "\n",
    "    real    0m3.567s\n",
    "    user    0m3.402s\n",
    "    sys     0m0.165s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressing data in the terminal via bzip2:\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time bzip2 -k zeros_100p\n",
    "\n",
    "    real    0m1.083s\n",
    "    user    0m1.010s\n",
    "    sys     0m0.073s\n",
    "    \n",
    "be131-40@meowth:~/lab7-claire$ time bzip2 -k zeros_90p\n",
    "\n",
    "    real    0m10.681s\n",
    "    user    0m10.549s\n",
    "    sys     0m0.132s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time bzip2 -k zeros_80p\n",
    "\n",
    "    real    0m12.020s\n",
    "    user    0m11.908s\n",
    "    sys     0m0.112s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time bzip2 -k zeros_70p\n",
    "\n",
    "    real    0m13.757s\n",
    "    user    0m13.597s\n",
    "    sys     0m0.160s\n",
    "    \n",
    "be131-40@meowth:~/lab7-claire$ time bzip2 -k zeros_60p\n",
    "\n",
    "    real    0m15.709s\n",
    "    user    0m15.592s\n",
    "    sys     0m0.116s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time bzip2 -k zeros_50p\n",
    "\n",
    "    real    0m16.629s\n",
    "    user    0m16.476s\n",
    "    sys     0m0.152s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressing data in the terminal via pbzip2:\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time pbzip2 -k zeros_100p\n",
    "\n",
    "    real    0m0.098s\n",
    "    user    0m1.654s\n",
    "    sys     0m0.112s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time pbzip2 -k zeros_90p\n",
    "\n",
    "    real    0m0.785s\n",
    "    user    0m19.142s\n",
    "    sys     0m0.705s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time pbzip2 -k zeros_80p\n",
    "\n",
    "    real    0m1.027s\n",
    "    user    0m25.722s\n",
    "    sys     0m0.847s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time pbzip2 -k zeros_70p\n",
    "\n",
    "    real    0m1.269s\n",
    "    user    0m31.928s\n",
    "    sys     0m0.801s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time pbzip2 -k zeros_60p\n",
    "\n",
    "    real    0m1.572s\n",
    "    user    0m39.997s\n",
    "    sys     0m1.200s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time pbzip2 -k zeros_50p\n",
    "\n",
    "    real    0m1.659s\n",
    "    user    0m45.202s\n",
    "    sys     0m1.291s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressing data in the terminal via Arithmetic Compress:\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time ArithmeticCompress zeros_100p zeros_100p.art\n",
    "\n",
    "    real    0m15.137s\n",
    "    user    0m14.912s\n",
    "    sys     0m0.225s\n",
    "\n",
    "be131-40@meowth:~/lab7-claire$ time ArithmeticCompress zeros_90p zeros_90p.art\n",
    "\n",
    "    real    0m28.913s\n",
    "    user    0m28.804s\n",
    "    sys     0m0.109s\n",
    "    \n",
    "be131-40@meowth:~/lab7-claire$ time ArithmeticCompress zeros_80p zeros_80p.art\n",
    "\n",
    "    real    0m39.217s\n",
    "    user    0m38.964s\n",
    "    sys     0m0.253s\n",
    "    \n",
    "be131-40@meowth:~/lab7-claire$ time ArithmeticCompress zeros_70p zeros_70p.art\n",
    "\n",
    "    real    0m40.122s\n",
    "    user    0m39.987s\n",
    "    sys     0m0.100s\n",
    "    \n",
    "be131-40@meowth:~/lab7-claire$ time ArithmeticCompress zeros_60p zeros_60p.art\n",
    "\n",
    "    real    0m41.975s\n",
    "    user    0m41.645s\n",
    "    sys     0m0.276s\n",
    "    \n",
    "be131-40@meowth:~/lab7-claire$ time ArithmeticCompress zeros_50p zeros_50p.art\n",
    "\n",
    "    real    0m43.430s\n",
    "    user    0m43.188s\n",
    "    sys     0m0.240s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary table of methods, file name, input file size, compressed file size, and real time count:\n",
    "\n",
    "| Method       | File Name | Input Size  | Output Size | Time\n",
    "| ----------|:-------------:| :-----:|:-----: | --------:\n",
    "| gzip      | zeros_100p | 105mb | 102kb | 0.739s\n",
    "| gzip      | zeros_90p | 105mb | 58.7mb | 0.002s\n",
    "| gzip      | zeros_80p | 105mb | 81.2mb | 20.362s\n",
    "| gzip      | zeros_70p | 105mb | 93.6mb | 6.207s\n",
    "| gzip      | zeros_60p | 105mb | 102mb | 4.312s\n",
    "| gzip      | zeros_50p | 105mb | 105mb | 3.567s\n",
    "| bzip2      | zeros_100p | 105mb | 107b | 1.083s\n",
    "| bzip2      | zeros_90p | 105mb | 61.2mb | 10.681s\n",
    "| bzip2      | zeros_80p | 105mb | 86.6mb | 12.020s\n",
    "| bzip2      | zeros_70p | 105mb | 99.8mb | 13.757s\n",
    "| bzip2      | zeros_60p | 105mb | 105mb | 15.709s\n",
    "| bzip2      | zeros_50p | 105mb | 105mb | 16.629s\n",
    "| pbzip2      | zeros_100p | 105mb | 5.38kb | 0.098s\n",
    "| pbzip2      | zeros_90p | 105mb | 61.2mb | 0.785s\n",
    "| pbzip2      | zeros_80p | 105mb | 86.7mb | 1.020s\n",
    "| pbzip2      | zeros_70p | 105mb | 99.8mb | 1.757s\n",
    "| pbzip2      | zeros_60p | 105mb | 105mb | 1.709s\n",
    "| pbzip2      | zeros_50p | 105mb | 105mb | 1.629s\n",
    "| ArithmeticCompress      | zeros_100p | 105mb | 1.03kb | 15.137s\n",
    "| ArithmeticCompress      | zeros_90p | 105mb | 49.2mb | 28.913s\n",
    "| ArithmeticCompress      | zeros_80p | 105mb | 75.7mb | 39.217s\n",
    "| ArithmeticCompress      | zeros_70p | 105mb | 92.4mb | 40.122s\n",
    "| ArithmeticCompress      | zeros_60p | 105mb | 102mb | 41.975s\n",
    "| ArithmeticCompress      | zeros_50p | 105mb | 105mb | 43.430s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary table for DNA and AA sequences:\n",
    "\n",
    "|Method      | File Name | Input Size  | Output Size | Time\n",
    "| ----------|:-------------:| :-----:|:-----: | --------:\n",
    "| gzip      | nt_seq.fa | 100mb | 29.2mb | 12.200s\n",
    "| gzip      | protein_seq.fa | 100mb | 60.6mb | 0m4.605s\n",
    "| bzip2      | nt_seq.fa | 100mb | 27.3mb | 12.200s\n",
    "| bzip2      | protein_seq.fa | 100mb | 55.2mb | 0m9.592s\n",
    "| pbzip2      | nt_seq.fa | 100mb | 27.3mb | 0m0.652s\n",
    "| pbzip2      | protein_seq.fa | 100mb | 55.3mb | 0m0.739s\n",
    "| Arithmetic Compress     | nt_seq.fa | 100mb | 25kb | 0m22.773s\n",
    "| Arithmetic Compress      | protein_seq.fa | 54mb | 102kb | 0m28.583s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "    \n",
    "Which algorithm achieves the best level of compression on each file type?\n",
    "    \n",
    "    Arithmetic Compress\n",
    "\n",
    "Which algorithm is the fastest?\n",
    "    \n",
    "    pzip2\n",
    "\n",
    "What is the difference between bzip2 andpbzip2? \n",
    "\n",
    "    pzip2 is a parallel implementation of bzip2, so it splits the processes of bzip2 and runs them simultaneously \n",
    "\n",
    "Do you expect one to be faster and why?\n",
    "\n",
    "    I expect pzip2 because it runs the same processes as bzip2 but splits them so they run simultaneously, so it should finish befor bzip2, which runs the processes one after another.\n",
    "\n",
    "How does the level of compression change as the percentage of zeros increases?Why does this happen?\n",
    "\n",
    "    As the percentage of zeros increases, the level of compression increases (compressed files get smaller). This is because the data become less random, since the amount of similarity (number of 0s) increases.\n",
    "\n",
    "What is the minimum number of bits required to store a single DNA base?\n",
    "\n",
    "    2 bits\n",
    "\n",
    "What is the minimum number of bits required to store an amino acid letter?\n",
    "\n",
    "    log2(20) bits\n",
    "\n",
    "In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences?\n",
    "\n",
    "    23700000 bits for DNA and 55200000 bits for proteins\n",
    "\n",
    "Are gzip and bzip2 performing well on DNA and proteins?\n",
    "\n",
    "    Yes - they are compressing files to about 1/4 and 1/2 their original sizes, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori, doyou expect to achieve better or worse compression here than random data? Why?\n",
    "\n",
    "    I would expect these to have better compression rates, since the data are not random (very similar to each other because they are homologs).\n",
    "\n",
    "\n",
    "Compressing gp120 homologs in the terminal:\n",
    "\n",
    "\n",
    "\n",
    "Summary table for gp120 compression:\n",
    "\n",
    "|Method      | File Name | Input Size  | Output Size | Time\n",
    "| ----------|:-------------:| :-----:|:-----: | --------:\n",
    "| gzip      | gp120.fa | 6.64kb | 896b | 0m4.623s\n",
    "| bzip2      | gp120.fa | 6.64kb | 1.07kb | 0m0.005s\n",
    "| pbzip2      | gp120.fa | 6.64kb | 1.07kb |  0m0.008s\n",
    "| Arithmetic Compress      | gp120.fa | 6.64kb | 3.59kb | 0m0.010s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the compression ratio of this file compare to random data?\n",
    "\n",
    "    The compression rates are better- about 1/6 the size of the original file, compared to 1/4 on the random data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make some assumptions about the contents of the data at your biotech company. Most of the data, say 80%, isre-sequencing of genomes and plasmids that are very similar to each other. Another 10% might be protein sequences, and the last 10% are binary microscope images which we’ll assume follow the worst-case scenario of being completely random.\n",
    "\n",
    "Given the benchmarking data you obtained in this lab, which algorithm do you propose to use for each type of data?\n",
    "\n",
    "    I would use pbzip2 for the nucleotide and protein sequences, since there 90% of data is in those categories and that algorithm is the fastest and compresses the data well.  I'd use Arithmetic Compress for the random data, since only 10% of the data is in that format, so the time cost of the algorithm would be mitigated by the high compression rate from the algorithm\n",
    "\n",
    "Provide an estimate for the fraction of space you can save using your compression scheme. \n",
    "\n",
    "    .8*(1/6)+.1(.5)+.1(.5) = .23 of starting amount\n",
    "\n",
    "How much of a bonus do you anticipate receiving this year?\n",
    "\n",
    "    $500*(100-23)= $38500 bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
